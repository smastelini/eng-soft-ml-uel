{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 2\n",
    "\n",
    "---\n",
    "\n",
    "**Saulo Martiello Mastelini**<br>\n",
    "Candidato a Ph.D. pelo ICMC-USP<br>\n",
    "Online Machine Learning\n",
    "\n",
    "Página pessoal: [smastelini](https://smastelini.github.io/)</br>\n",
    "e-mail: saulomastelini@gmail.com\n",
    "\n",
    "---\n",
    "\n",
    "## Sumário:\n",
    "\n",
    "- Algoritmos baseados em distância\n",
    "- Particionamento de dados para avaliação: Holdout e Holdout repetido\n",
    "- Métricas de avaliação para classificação\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc  # Classes abstratas (mais sobre isso depois)\n",
    "\n",
    "import numpy as np   # Math\n",
    "import pandas as pd  # Dados\n",
    "\n",
    "import plotly.express as px  # Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification  # Geração de datasets\n",
    "from sklearn import metrics  # Metrics\n",
    "from sklearn.model_selection import train_test_split  # Split dos dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Contextualização"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir alguns vetores para teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([2, 3])\n",
    "c = np.array([3, 5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precisamos definir a nossa noção de distância\n",
    "- Exemplos\n",
    "- Com o que estamos lidando aqui?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=[a[0], b[0], c[0]], y=[a[1], b[1], c[1]])\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Espaço 2D\n",
    "    - Tipicamente lidamos com espaços N-dimensionais\n",
    "- Precisamos de medidas para calcular distâncias\n",
    "- Vamos começar com uma métrica de distância muito famosa: Distância Euclidiana\n",
    "    - $dist_{l2}(\\vec{u}, \\vec{v}) = \\sqrt{\\sum_i^n (u_i - v_i) ^2}$\n",
    "- Vamos usar o numpy para nos ajudar com as funções matemáticas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(v1, v2):\n",
    "    sq_diff = (v1 - v2) ** 2\n",
    "\n",
    "    # Condicional para tratar tanto vetores quanto matrizes\n",
    "    if len(v1.shape) > 1:\n",
    "        sq_diff = np.sum(sq_diff, axis=1)\n",
    "    else:\n",
    "        sq_diff = np.sum(sq_diff)\n",
    "    return sq_diff ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist(b, c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos tirar proveito da vetorização!\n",
    "    - O que é isso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([[1, 2], [3, 4]])\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist(d, a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cenário mais realístico - parte 1**\n",
    "\n",
    "- Vamos imaginar um cenário mais prático\n",
    "- Vários pontos num espaço N-dimensional (o nosso dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array(\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [2, 3, 4],\n",
    "        [3, 4, 7],\n",
    "        [3, 5, 2]\n",
    "    ]\n",
    ")\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(x=e[:, 0], y=e[:, 1], z=e[:, 2])\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_dist(e, np.array([1.5, 2.9, 8.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_dist(v1, v2):\n",
    "    abs_diff = np.abs(v1 - v2)\n",
    "\n",
    "    # Condicional para tratar tanto vetores quanto matrizes\n",
    "    if len(v1.shape) > 1:\n",
    "        abs_diff = np.sum(abs_diff, axis=1)\n",
    "    else:\n",
    "        abs_diff = np.sum(abs_diff)\n",
    "    return abs_diff\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Outra alternativa é a distância Manhattan:\n",
    "    - $dist_{l1}(\\vec{u}, \\vec{v}) = \\sum_i^n |u_i - v_i|$\n",
    "- Podemos generalizar várias medidas de distância através da distância Minkowski:\n",
    "    - $dist_{lp}(\\vec{u}, \\vec{v}) = (\\sum_i^n |u_i - v_i| ^ p) ^ \\frac{1}{p}$\n",
    "- A distância cosseno é útil em aplicações que utilizam dados textuais:\n",
    "    - $dist_{\\cos} = \\cos(\\theta) = \\dfrac{\\vec{u} \\cdot \\vec{v}}{\\|\\vec{u}\\|\\|\\vec{u}\\|} = \\dfrac{\\sum_i^n u_i v_i}{\\sqrt{\\sum_i^n u_i ^ 2}\\sqrt{\\sum_i^n v_i ^ 2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_dist(e, np.array([1.5, 2.9, 8.0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cenário mais realístico - parte 2**\n",
    "\n",
    "- Cada ponto tem uma medida de interesse que queremos prever para observações futuras\n",
    "    - Classificação\n",
    "    - Regressão\n",
    "\n",
    "\n",
    "## 2. k-Nearest Neighbors\n",
    "\n",
    "- k-Vizinhos mais próximos:\n",
    "    - Calcula a distância de novos pontos para a base de dados\n",
    "    - Utiliza a informação dos $k$ vizinhos mais próximos para obter a resposta final \n",
    "- Algoritmo _lazy_ ou preguiçoso\n",
    "    - Por quê?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseKNN(abc.ABC):\n",
    "    def __init__(self, k, p, verbose):\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "        self.verbose = verbose\n",
    "\n",
    "        assert isinstance(k, int) and k >= 1\n",
    "\n",
    "    def _minkowski_dist(self, x_new):\n",
    "        return np.sum(np.abs(self._X - x_new) ** self.p, axis=1) ** (1 / self.p)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.verbose:\n",
    "            print(\"Vou fingir que trabalho.\")\n",
    "\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"\\tUfa, que canseira!\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    abc.abstractmethod\n",
    "    def predict(self, X_new):\n",
    "        pass\n",
    "\n",
    "\n",
    "class KNNClassifier(BaseKNN):\n",
    "    def __init__(self, k=3, p=2, verbose=False):\n",
    "        super().__init__(k, p, verbose)\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        y_pred = np.zeros(len(X_new), dtype=int)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Hora de predizer:\")\n",
    "\n",
    "        for i in range(len(X_new)):\n",
    "            dists = self._minkowski_dist(X_new[i, :])\n",
    "            order = np.argsort(dists)\n",
    "            top_k = order[:self.k]\n",
    "\n",
    "            # A classificação acontece aqui\n",
    "            y_pred[i] = np.argmax(np.bincount(self._y[top_k]))\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"Instância de predição {i} | Vizinhos mais próximos: {top_k} | R: {y_pred[i]}\")\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "class KNNRegressor(BaseKNN):\n",
    "    def __init__(self, k=3, p=2, verbose=False):\n",
    "        super().__init__(k, p, verbose)\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        y_pred = np.zeros(len(X_new))\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Hora de predizer:\")\n",
    "\n",
    "        for i in range(len(X_new)):\n",
    "            dists = self._minkowski_dist(X_new[i, :])\n",
    "            order = np.argsort(dists)\n",
    "            top_k = order[:self.k]\n",
    "\n",
    "            # A regressão acontece aqui\n",
    "            y_pred[i] = np.mean(self._y[top_k])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"Instância de predição {i} | Vizinhos mais próximos: {top_k} | R: {y_pred[i]}\")\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pd.DataFrame(X, columns=[\"x1\", \"x2\"])\n",
    "vis[\"Classe\"] = y\n",
    "vis[\"Classe\"] = vis[\"Classe\"].astype(\"category\")\n",
    "\n",
    "fig = px.scatter(\n",
    "    vis, x=\"x1\", y=\"x2\", color=\"Classe\", symbol=\"Classe\")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Notas sobre avaliação de modelos de ML, _overfitting_, _undefitting_.\n",
    "\n",
    "- Não podemos utilizar todos os dados disponíveis num primeiro momento\n",
    "- Precisamos ter uma estimativa de performance do nosso modelo treinado\n",
    "\n",
    "- > **Desafio:** Por que utilizar todos os dados os dados para treinar e testar é uma má ideia?\n",
    "\n",
    "\n",
    "### 3.1. Sobre e subajuste de modelos\n",
    "\n",
    "- Queremos que o modelo seja capaz de generalizar os dados de treinamento\n",
    "    - Aprender os padrões que governam a relação entre X e y\n",
    "    - Na vida é assim:\n",
    "        - Não podemos focar demais nos detalhes insignificantes\n",
    "        - Tampouco sermos superficiais demais\n",
    "\n",
    "\n",
    "<img src=\"img/a2/tradeoff.jpg\" width=\"700\">\n",
    "    <figcaption>Overfitting, underfitting e o dilema do Viés e Variância. Fonte: <a href=\"https://stats.stackexchange.com/questions/543509/why-test-error-and-variance-has-different-curve-in-bias-variance-trade-off-graph)\">stats.stackexchange.com</a></figcaption>\n",
    "</img>\n",
    "\n",
    "Os dois desafios a se evitar durante a modelagem:\n",
    "\n",
    "1. Overfitting: O modelo está focando demais em excesso nos dados de treinamento e não está aprendendo, de fato, o problema\n",
    "    - O modelo demasiadamente complexo e sem estratégias de regularização (algo como um sistema de frenagem, que limita a \"velocidade\")\n",
    "    - Ex: estudante que decora toda a matéria, mas se na prova algum detalhe é diferente, não sabe resolver\n",
    "    - Alta variância: pequenas alterações nos dados acarretam grandes mudanças no modelo\n",
    "    - *Sintomas:*\n",
    "        - Erro de treinamento muito baixo\n",
    "        - Erro de teste muito alto\n",
    "    - Observação: se o seu erro de testes está bom demais para ser verdade:\n",
    "        - Pode ser que exista _\"data leakage\"_\n",
    "        - Dados de teste estão vazando para o treinamento\n",
    "2. Undefitting: O modelo não está conseguindo aprender os padrões\n",
    "    - Modelo demasiadamente simples para o problema\n",
    "    - Ex: uma reta para explicar o comportamento de uma parábola\n",
    "    - Alto viés: o modelo é \"teimoso\" e insensível a variações dos dados\n",
    "    - *Sintomas:*\n",
    "        - Erros de validação e treinamento são parecidos (e altos)\n",
    "\n",
    "\n",
    "- Queremos um balanço:\n",
    "- Em geral:\n",
    "    - Erro de treino ligeiramente inferior que o erro de validação\n",
    "    - Baixo erro de validação\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2. Particionamento de dados: _Holdout_\n",
    "\n",
    "- Em geral, utilizamos alguma estratégia de avaliação para separar os dados entre treinamento e teste/validação\n",
    "    - Obter medidas de avaliação mais fidedignas com a realidade que o modelo vai enfrentar na \"vida real\"\n",
    "- Holdout: Aplica uma partição (aleatória) entre os dados para criar conjuntos de treino e teste\n",
    "    - Normalmente baseada em porcentagem. Por exemplo: 30% dos dados serão utilizados para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Para pensar:** quais as limitações dessa abordagem?\n",
    "\n",
    "Possível solução:\n",
    "\n",
    "- Holdout repetido:\n",
    "    - Aplica várias partições holdout, variando a seed aleatória\n",
    "    - Modelos treinados para cada partição\n",
    "    - Agrega os resultados obtidos: média, desvio padrão, etc.\n",
    "- Qual a limitação dessa abordagem? (Ela resolve o problema parcialmente, mas o que ainda falta?)\n",
    "- No decorrer do curso veremos abordagens mais adequadas para avaliação\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Aplicando o Holdout no nosso modelo k-NN para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_c = KNNClassifier(verbose=True)\n",
    "knn_c.fit(X_train, y_train)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_c.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Métricas de avaliação para classificação\n",
    "\n",
    "- Permitem avaliar o modelo preditivo\n",
    "- Várias métricas, a depender da necessidade\n",
    "- **Acurácia:** percentual de acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuracia(y_true, y_pred):\n",
    "    return sum(y_true == y_pred) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A acurácia pode ser problemática\n",
    "- Suponha que tenhamos um cenário altamente desbalanceado\n",
    "    - A proporção de exemplos de cada classe é altamente desigual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = np.zeros(100, dtype=int)\n",
    "ex[3] = 1\n",
    "ex[10] = 1\n",
    "ex[39] = 1\n",
    "\n",
    "acuracia(ex, np.zeros(100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- E se o label \"1\" for o que mais estamos interessados?\n",
    "- Exemplos: fraude, ataque hacker, anomalia, etc.\n",
    "- Precisamos de mais métricas para avaliar nossos modelos!\n",
    "- Matriz de confusão: a raiz de (quase) todas as métricas de classificação\n",
    "\n",
    "<img src=\"img/a2/matriz-confusao.png\" width=\"500\">\n",
    "    <figcaption>Matriz de Confusão: contagem de erros e acertos do classificador por tipo</figcaption>\n",
    "</img>\n",
    "\n",
    "- A matriz é organizada da seguinte forma:\n",
    "    - TP: Verdadeiro positivo\n",
    "    - FP: Falso positivo\n",
    "    - TN: Verdadeiro negativo\n",
    "    - FN: Falso negativo\n",
    "- No caso em que temos mais do que duas classes, a matriz de confusão tem linhas e colunas correspondentes a cada classe\n",
    "    - Em geral, calculamos as métricas considerando cada classe como o \"Positivo\" e as demais como \"Negativo\"\n",
    "    - Podemos, por exemplo, tirar a média das métricas por classe para obter um valor final\n",
    "\n",
    "**Populares métricas derivadas da matriz de confusão:**\n",
    "\n",
    "1. Acurácia: mede o desempenho geral\n",
    "    $$Accuracy = \\dfrac{TP + TN}{TP + TN + FP + FN}$$\n",
    "2. Precisão (P)\n",
    "    $$\\text{Precision} = \\dfrac{TP}{FP + TP}$$\n",
    "3. Recall ou Revocação (R)\n",
    "    $$\\text{Recall} = \\dfrac{TP}{TP + TN}$$\n",
    "4. F1-score\n",
    "    $$F1 = \\dfrac{2 \\times P \\times R}{P + R}$$\n",
    "\n",
    "<img src=\"img/a2/alvo.jpg\" height=\"500\">\n",
    "    <figcaption>Acurácia vs. Precisão</figcaption>\n",
    "</img>\n",
    "\n",
    "- Existem outras medidas que são focadas em tarefas específicas\n",
    "- Por exemplo: tarefas de classificação desbalanceadas\n",
    "    - Acurácia balanceada\n",
    "- Se quiser aprender muito mais sobre métricas: [[artigo] A review on evaluation metrics for data classification evaluations](https://d1wqtxts1xzle7.cloudfront.net/37219940/5215ijdkp01-libre.pdf?1428316763=&response-content-disposition=inline%3B+filename%3DA_REVIEW_ON_EVALUATION_METRICS_FOR_DATA.pdf&Expires=1677429173&Signature=VilOIgvDEIvWbQXs6LRcn1oAzNYEhMfIl9wE5~ZUeosVg8qSgssMosoI~MNRgBXmMjpgTEFfC623ebmjS5HIy3t2fZgcPQbyWMFDI7fyJxbGKbmgpInFosxecYcZ0AvbXxoQbmxdOH28H7cItGy3nbw56wxywDVRLh~CZGYbwsZ3eoAoha4e3XBTCC~l8zX2yr-JwF5dT~PQNaQxyw~2zNs3hcgxhCeUCT9Ay~TFnNJ0Zsev5drG5kZdzxH5oJsW61g9~rkUpgVzDbfj3ZATj1wI1vGw8lho2gHASz2f0BJedB25N5VWtR4WIgW-k4B5vjyToaAGqzh1OKLD5HsA5A__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parâmetro `average` | Descrição                                                                                                          |\n",
    "|---------------------|--------------------------------------------------------------------------------------------------------------------|\n",
    "| `binary`            | Reporta resultados apenas para a _label_ passada em `pos_label`. Só aplicável em tarefas de classificação binária. |\n",
    "| `micro`             | Calcula a média geral de TP, TN, FP e FN.                                                                          |\n",
    "| `macro`             | Calcula a métrica por classe e toma a média entre as métricas calculadas.                                          |\n",
    "| `weighted`          | Calcula a métrica por classe e faz média ponderada pelo suporte (número de exemplos em cada classe).               |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fronteiras de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptado de: https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Utilities/ML-Python-utils.py\n",
    "\n",
    "def plot_decision_boundaries(X, y, model_class, **model_params):\n",
    "    \"\"\"Function to plot the decision boundaries of a classification model.\n",
    "\n",
    "    This uses just the first two columns of the data for fitting \n",
    "    the model as we need to find the predicted value for every point in \n",
    "    scatter plot.\n",
    "    Arguments:\n",
    "            X: Feature data as a NumPy-type array.\n",
    "            y: Label data as a NumPy-type array.\n",
    "            model_class: A Scikit-learn ML estimator class \n",
    "            e.g. GaussianNB (imported from sklearn.naive_bayes) or\n",
    "            LogisticRegression (imported from sklearn.linear_model)\n",
    "            **model_params: Model parameters to be passed on to the ML estimator\n",
    "    \n",
    "    Typical code example:\n",
    "            plt.figure()\n",
    "            plt.title(\"KNN decision boundary with neighbros: 5\",fontsize=16)\n",
    "            plot_decision_boundaries(X_train,y_train,KNeighborsClassifier,n_neighbors=5)\n",
    "            plt.show()\n",
    "    \"\"\"\n",
    "    from matplotlib import colormaps\n",
    "    import matplotlib.markers as mmarkers\n",
    "    def mscatter(x, y, ax=None, m=None, **kw):\n",
    "        if not ax: ax=plt.gca()\n",
    "        sc = ax.scatter(x,y,**kw)\n",
    "        if (m is not None) and (len(m)==len(x)):\n",
    "            paths = []\n",
    "            for marker in m:\n",
    "                if isinstance(marker, mmarkers.MarkerStyle):\n",
    "                    marker_obj = marker\n",
    "                else:\n",
    "                    marker_obj = mmarkers.MarkerStyle(marker)\n",
    "                path = marker_obj.get_path().transformed(\n",
    "                            marker_obj.get_transform())\n",
    "                paths.append(path)\n",
    "            sc.set_paths(paths)\n",
    "        return sc\n",
    "\n",
    "    try:\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).flatten()\n",
    "    except:\n",
    "        print(\"Coercing input data to NumPy arrays failed\")\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "\n",
    "    # Reduces to the first two columns of data\n",
    "    reduced_data = X[:, :2]\n",
    "    # Instantiate the model object\n",
    "    model = model_class(**model_params)\n",
    "    # Fits the model with the reduced data\n",
    "    model.fit(reduced_data, y)\n",
    "\n",
    "    # Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "    h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].    \n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "    # Meshgrid creation\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Obtain labels for each point in mesh using the model.\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])    \n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    # Predictions to obtain the classification results\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    # Right now it only works with binary tasks: expand both dictionaries or use cmap for multiclass tasks\n",
    "\n",
    "    cmap = colormaps['viridis']\n",
    "\n",
    "    markers = {0: \"o\", 1: \"^\", 2: \"s\", 3: \"D\", 4: \"+\", 5: \"*\"}\n",
    "\n",
    "    m = list(map(lambda i: markers[i], y))\n",
    "    \n",
    "    # Plotting\n",
    "    plt.contourf(xx, yy, Z, alpha=0.5, cmap=cmap)\n",
    "    mscatter(x=X[:, 0], y=X[:, 1], c=y, m=m, cmap=cmap)\n",
    "    \n",
    "    plt.xlabel(\"x1\",fontsize=15)\n",
    "    plt.ylabel(\"x2\",fontsize=15)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(X_train, y_train, KNNClassifier, k=3, p=2, verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos a implementação do sklearn para obter mais velocidade e outras otimizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(X_train, y_train, KNeighborsClassifier, n_neighbors=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foco nos seguintes exemplos:\n",
    "\n",
    "- k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(X_train, y_train, KNeighborsClassifier, n_neighbors=50)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(X_train, y_train, KNeighborsClassifier, n_neighbors=1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Algoritmos baseados em distância e escala\n",
    "\n",
    "- Os dados que utilizamos até aqui possuem a mesma escala nos dados\n",
    "- Mas e se esse não fosse o caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Aumento a escala da primeira feature\n",
    "X[:, 0] *= 100.0 \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = KNeighborsClassifier()\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, cls.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora?\n",
    "\n",
    "- Feature scaling!!\n",
    "- Padronizamos as features para garantir que todas tenham a mesma importância para o modelo.\n",
    "- Scaling é essencial para todo algoritmo baseado em distância\n",
    "- Existem vários scalers disponíveis no sklearn\n",
    "    - Vale a pena explorar a documentação\n",
    "    - Soluções mais populares: `MinMaxScaler` (entre 0 e 1) e `StandarScaler` (z-score)\n",
    "    - z-score:\n",
    "        $$\\tilde{x} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "    - Para dados com outlier, z-score é uma escolha melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, cls.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa:\n",
    "\n",
    "1. Descreva com suas palavras os fenômenos que estão acontecendo em cada um exemplos acima. Dica: comentamos durante a aula sobre esses problemas.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Em problemas de classificação, é uma boa ideia utilizar valores ímpares para `k` no k-NN. Comente com as suas palavras sobre isso. Qual é o motivo dessa escolha?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecc03869faa965a79c0f9cb0e2d41545d4cdd523e34946938b45eb81f66572dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
